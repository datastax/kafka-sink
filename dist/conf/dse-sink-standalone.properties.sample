name=dse-sink
connector.class=com.datastax.kafkaconnector.DseSinkConnector
tasks.max=1

# Topics to subscribe to, comma-delimited.
topics=my_topic

# Comma-separated list of DSE cluster contact points. Used by the DataStax Driver to discover
# DSE cluster topology. Defaults to empty, meaning localhost.
#contactPoints=[]

# DSE data center name to which the DataStax Driver connects. Required if contactPoints
# is specified.
#loadBalancing.localDc=

# Native transport port to connect to on DSE nodes; defaults to 9042.
#port=9042

# Maximum number of requests to send to DSE at a single time. Defaults to 500.
#maxConcurrentRequests=500

# Maximum number of records that could be send in one batch request to DSE
#maxNumberOfRecordsInBatch=32

# Number of connections that driver maintains within a connection pool to each node in local dc
#connectionPoolLocalSize=4

# CQL statement execution timeout, in seconds. Defaults to 30 seconds.
#queryExecutionTimeout=30

# Whether or not to enable stats reporting through JMX. Defaults to true.
#jmx=true

# Compression algorithm to use when issuing requests to DSE. Valid values are
# None, Snappy, LZ4. Defaults to None.
#compression=None

### Authentication Setings ###

# Authentication provider to use, if any. Valid choices: None, DSE, GSSAPI.
# Defaults to None.
#auth.provider=None

# Username for DSE provider authentication
#auth.username=

# Password for DSE provider authentication
#auth.password=

# Kerberos keytab file
#auth.gssapi.keyTab=

# Kerberos principal
#auth.gssapi.principal=

# SASL service name to use for GSSAPI provider authentication.
# Defautls to dse.
#auth.gssapi.service=dse

### SSL Settings ###

# SSL provider to use, if any. Valid choices: None, JDK, OpenSSL.
# Defaults to None.
#ssl.provider=None

# Comma-separated list of cipher suites to enable.
#ssl.cipherSuites=

# Whether or not to validate DSE node hostnames when using SSL.
# Defaults to true.
#ssl.hostnameValidation=true

# Keystore password.
#ssl.keystore.password=

# Path to the keystore file.
#ssl.keystore.path=

# Truststore password.
#ssl.truststore.password=

# Path to the truststore file.
#ssl.truststore.path=

# Path to the SSL certificate file, when using OpenSSL.
#ssl.openssl.keyCertChain=

# Path to the private key file, when using OpenSSL.
#ssl.openssl.privateKey=

### Settings for topic my_topic ###

#### Settings for table my_ks.my_table in topic my_topic ####

# Kafka record field to DSE table column mapping spec, in the form 'col1=value.f1, col2=key.f1'.
topic.my_topic.my_ks.my_table.mapping=col1=key.f1, col2=value.f1

# Query consistency level; defaults to LOCAL_ONE.
#topic.my_topic.my_ks.my_table.consistencyLevel=LOCAL_ONE

# Time-to-live. Set to the number of seconds before the data is automatically deleted in DSE.
# Defaults to -1 (disabled).
#topic.my_topic.my_ks.my_table.ttl=-1

# Whether to treat nulls in Kafka as UNSET in DSE. DataStax recommends using the default to
# avoid creating unnecessary tombstones. Defaults to true.
#topic.my_topic.my_ks.my_table.nullToUnset=true

# When enabled, treat records that after mapping would result in only non-null values for
# primary key columns as deletes, rather than inserting/updating nulls for all regular columns.
# Note that for this behavior to trigger, the mapping specification must map all columns in the
# table. Defaults to true.
#topic.my_topic.my_ks.my_table.deletesEnabled=true

#### Record decoding settings in topic my_topic ####
# Locale to use for locale-sensitive conversions. Defaults to en_US.
#topic.my_topic.codec.locale=en_US

# The time zone to use for temporal conversions that do not convey any explicit time zone
# information. Defaults to UTC.
#topic.my_topic.codec.timeZone=UTC

# The temporal pattern to use for `String` to CQL `timestamp` conversion. Valid choices:
#
# - A date-time pattern such as `yyyy-MM-dd HH:mm:ss`.
# - A pre-defined formatter such as `ISO_ZONED_DATE_TIME` or `ISO_INSTANT`. Any public static
#   field in `java.time.format.DateTimeFormatter` can be used.
# - The special formatter `CQL_TIMESTAMP`, which is a special parser that accepts all valid CQL
#   literal formats for the `timestamp` type.
# Defaults to CQL_TIMESTAMP.
#topic.my_topic.codec.timestamp=CQL_TIMESTAMP

# The temporal pattern to use for `String` to CQL `date` conversion. Valid choices:
#
# - A date-time pattern such as `yyyy-MM-dd`.
# - A pre-defined formatter such as `ISO_LOCAL_DATE`. Any public static field in
#   `java.time.format.DateTimeFormatter` can be used.
# Defaults to ISO_LOCAL_DATE.
#topic.my_topic.codec.date=ISO_LOCAL_DATE

# The temporal pattern to use for `String` to CQL `time` conversion. Valid choices:
#
# - A date-time pattern, such as `HH:mm:ss`.
# - A pre-defined formatter, such as `ISO_LOCAL_TIME`. Any public static field in
#   `java.time.format.DateTimeFormatter` can be used.
# Defaults to ISO_LOCAL_TIME.
#topic.my_topic.codec.time=ISO_LOCAL_TIME

# If the input is a string containing only digits that cannot be parsed using the
# `codec.timestamp` format, the specified time unit is applied to the parsed value. All
# `TimeUnit` enum constants are valid choices.
# Defaults to MILLISECONDS.
#topic.my_topic.codec.unit=MILLISECONDS
